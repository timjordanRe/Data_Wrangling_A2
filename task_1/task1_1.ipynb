{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Detecting and Fixing Errors in dirty_data.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General approach\n",
    "Look for potential dirty data in the following areas:\n",
    "- integrity constraints\n",
    "- data entry error\n",
    "- wrong categorical data\n",
    "- violation of referential integrity\n",
    "- duplicated data\n",
    "- go against value range\n",
    "- wrong encoding\n",
    "- wrong representations\n",
    "- wrong names and numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_data_path = \"data\\Group109_dirty_data.csv\"\n",
    "missing_data_path = \"data\\Group109_missing_data.csv\"\n",
    "branch_path = r\"data\\branches.csv\"\n",
    "edges_path = \"data\\edges.csv\"\n",
    "nodes_path = r\"data\\nodes.csv\"\n",
    "\n",
    "dirty_df = pd.read_csv(dirty_data_path)\n",
    "missing_df = pd.read_csv(missing_data_path)\n",
    "branch_df = pd.read_csv(branch_path)\n",
    "edges_df = pd.read_csv(edges_path)\n",
    "nodes_df = pd.read_csv(nodes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>branch_code</th>\n",
       "      <th>branch_name</th>\n",
       "      <th>branch_lat</th>\n",
       "      <th>branch_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NS</td>\n",
       "      <td>Nickolson</td>\n",
       "      <td>-37.773803</td>\n",
       "      <td>144.983647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TP</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>-37.861835</td>\n",
       "      <td>144.905716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BK</td>\n",
       "      <td>Bakers</td>\n",
       "      <td>-37.815834</td>\n",
       "      <td>145.046450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  branch_code branch_name  branch_lat  branch_lon\n",
       "0          NS   Nickolson  -37.773803  144.983647\n",
       "1          TP    Thompson  -37.861835  144.905716\n",
       "2          BK      Bakers  -37.815834  145.046450"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   order_id                 500 non-null    object \n",
      " 1   date                     500 non-null    object \n",
      " 2   time                     500 non-null    object \n",
      " 3   order_type               500 non-null    object \n",
      " 4   branch_code              500 non-null    object \n",
      " 5   order_items              500 non-null    object \n",
      " 6   order_price              500 non-null    float64\n",
      " 7   customer_lat             500 non-null    float64\n",
      " 8   customer_lon             500 non-null    float64\n",
      " 9   customerHasloyalty?      500 non-null    int64  \n",
      " 10  distance_to_customer_KM  500 non-null    float64\n",
      " 11  delivery_fee             500 non-null    float64\n",
      "dtypes: float64(5), int64(1), object(6)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dirty_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_price</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>customerHasloyalty?</th>\n",
       "      <th>distance_to_customer_KM</th>\n",
       "      <th>delivery_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>480.712900</td>\n",
       "      <td>-30.753946</td>\n",
       "      <td>143.504403</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>8.629274</td>\n",
       "      <td>13.877162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>254.034843</td>\n",
       "      <td>25.337436</td>\n",
       "      <td>16.299630</td>\n",
       "      <td>0.302951</td>\n",
       "      <td>1.596279</td>\n",
       "      <td>2.378285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>31.750000</td>\n",
       "      <td>-37.827188</td>\n",
       "      <td>-37.822231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.613000</td>\n",
       "      <td>5.646222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>300.625000</td>\n",
       "      <td>-37.818738</td>\n",
       "      <td>144.952786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.750500</td>\n",
       "      <td>12.660927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>434.250000</td>\n",
       "      <td>-37.811755</td>\n",
       "      <td>144.963914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.639500</td>\n",
       "      <td>13.849738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>633.250000</td>\n",
       "      <td>-37.804505</td>\n",
       "      <td>144.980037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.633500</td>\n",
       "      <td>15.229668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1361.500000</td>\n",
       "      <td>145.005221</td>\n",
       "      <td>145.015449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.735000</td>\n",
       "      <td>20.088572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       order_price  customer_lat  customer_lon  customerHasloyalty?  \\\n",
       "count   500.000000    500.000000    500.000000           500.000000   \n",
       "mean    480.712900    -30.753946    143.504403             0.102000   \n",
       "std     254.034843     25.337436     16.299630             0.302951   \n",
       "min      31.750000    -37.827188    -37.822231             0.000000   \n",
       "25%     300.625000    -37.818738    144.952786             0.000000   \n",
       "50%     434.250000    -37.811755    144.963914             0.000000   \n",
       "75%     633.250000    -37.804505    144.980037             0.000000   \n",
       "max    1361.500000    145.005221    145.015449             1.000000   \n",
       "\n",
       "       distance_to_customer_KM  delivery_fee  \n",
       "count               500.000000    500.000000  \n",
       "mean                  8.629274     13.877162  \n",
       "std                   1.596279      2.378285  \n",
       "min                   3.613000      5.646222  \n",
       "25%                   7.750500     12.660927  \n",
       "50%                   8.639500     13.849738  \n",
       "75%                   9.633500     15.229668  \n",
       "max                  13.735000     20.088572  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>order_type</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>order_items</th>\n",
       "      <th>order_price</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>customerHasloyalty?</th>\n",
       "      <th>distance_to_customer_KM</th>\n",
       "      <th>delivery_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORDX02948</td>\n",
       "      <td>2018-03-11</td>\n",
       "      <td>10:11:49</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Cereal', 4), ('Eggs', 3), ('Coffee', 1), ('...</td>\n",
       "      <td>206.00</td>\n",
       "      <td>-37.805040</td>\n",
       "      <td>144.963243</td>\n",
       "      <td>0</td>\n",
       "      <td>7.615</td>\n",
       "      <td>14.403915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORDC07988</td>\n",
       "      <td>2018-03-06</td>\n",
       "      <td>10:01:41</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Coffee', 2), ('Cereal', 5), ('Eggs', 10), (...</td>\n",
       "      <td>437.00</td>\n",
       "      <td>-37.815989</td>\n",
       "      <td>144.983435</td>\n",
       "      <td>0</td>\n",
       "      <td>8.914</td>\n",
       "      <td>13.807773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORDI00568</td>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>14:05:04</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Fries', 6), ('Chicken', 5), ('Salad', 7), (...</td>\n",
       "      <td>507.40</td>\n",
       "      <td>-37.806281</td>\n",
       "      <td>144.941960</td>\n",
       "      <td>1</td>\n",
       "      <td>9.316</td>\n",
       "      <td>15.028384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORDI06756</td>\n",
       "      <td>2018-04-23</td>\n",
       "      <td>11:43:05</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Coffee', 3), ('Pancake', 6), ('Eggs', 3)]</td>\n",
       "      <td>234.00</td>\n",
       "      <td>-37.822259</td>\n",
       "      <td>144.946977</td>\n",
       "      <td>0</td>\n",
       "      <td>9.975</td>\n",
       "      <td>15.217270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORDX01986</td>\n",
       "      <td>2018-04-29</td>\n",
       "      <td>11:53:14</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Coffee', 6), ('Cereal', 1), ('Eggs', 2), ('...</td>\n",
       "      <td>134.25</td>\n",
       "      <td>-37.815950</td>\n",
       "      <td>144.986001</td>\n",
       "      <td>0</td>\n",
       "      <td>6.038</td>\n",
       "      <td>13.677500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id        date      time order_type branch_code  \\\n",
       "0  ORDX02948  2018-03-11  10:11:49  Breakfast          BK   \n",
       "1  ORDC07988  2018-03-06  10:01:41  Breakfast          NS   \n",
       "2  ORDI00568  2018-07-05  14:05:04      Lunch          NS   \n",
       "3  ORDI06756  2018-04-23  11:43:05  Breakfast          NS   \n",
       "4  ORDX01986  2018-04-29  11:53:14  Breakfast          BK   \n",
       "\n",
       "                                         order_items  order_price  \\\n",
       "0  [('Cereal', 4), ('Eggs', 3), ('Coffee', 1), ('...       206.00   \n",
       "1  [('Coffee', 2), ('Cereal', 5), ('Eggs', 10), (...       437.00   \n",
       "2  [('Fries', 6), ('Chicken', 5), ('Salad', 7), (...       507.40   \n",
       "3       [('Coffee', 3), ('Pancake', 6), ('Eggs', 3)]       234.00   \n",
       "4  [('Coffee', 6), ('Cereal', 1), ('Eggs', 2), ('...       134.25   \n",
       "\n",
       "   customer_lat  customer_lon  customerHasloyalty?  distance_to_customer_KM  \\\n",
       "0    -37.805040    144.963243                    0                    7.615   \n",
       "1    -37.815989    144.983435                    0                    8.914   \n",
       "2    -37.806281    144.941960                    1                    9.316   \n",
       "3    -37.822259    144.946977                    0                    9.975   \n",
       "4    -37.815950    144.986001                    0                    6.038   \n",
       "\n",
       "   delivery_fee  \n",
       "0     14.403915  \n",
       "1     13.807773  \n",
       "2     15.028384  \n",
       "3     15.217270  \n",
       "4     13.677500  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in the assignment brief, we will not be looking for any fixing values within the following columns as there are no errors in dirty data for them:\n",
    "- `order_id`\n",
    "- `time`\n",
    "- the numeric quantity in `order_items`\n",
    "- `delivery_fee`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] check if dates, time is properly formatted\n",
    "- [x] check if branch code is correct\n",
    "- [ ] check if order price makes sense according to number of items ordered\n",
    "- [ ] check if distance to customer is calculated properly in shortest distance\n",
    "- [ ] check if customer_lat and customer_lon exist in nodes\n",
    "- [x] check if order_type is correct according to time\n",
    "- [ ] check if customer does / does not have loyalty according to delivery fee ()\n",
    "\n",
    "\n",
    "Delivery fee is calculated using a different method for each branch.\n",
    "The fee depends linearly (but in different ways for each branch) on:\n",
    "a. weekend or weekday (1 or 0) - as a continuous variable\n",
    "b. time of the day (morning 0, afternoon 1, evening 2) - as a continuous variable\n",
    "c. distance between branch and customer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TP    169\n",
       "NS    163\n",
       "BK    144\n",
       "ns     11\n",
       "tp      7\n",
       "bk      6\n",
       "Name: branch_code, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df['branch_code'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above, we can see that some of the branch codes have been inputted in the wrong representation. Instead of being inputted in all uppercase, some of the values are shown as lowercase. We will need to perform data transformation on this column to convert all values to uppercase letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_df['branch_code'] = dirty_df['branch_code'].apply(str.upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the assignment brief, all string date values in column `date` should be in the format YYYY-MM-DD. We can verify if this is the case by using `pd.to_datetime` function on the `date` column and see if all date values fit the format `%Y-%m-%d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred. Unable to convert the following date:\n",
      "time data 06-10-2018 doesn't match format specified\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pd.to_datetime(dirty_df['date'], format='%Y-%m-%d', errors='raise')\n",
    "except ValueError as e:\n",
    "    print(\"Error occurred. Unable to convert the following date:\")\n",
    "    print(e)\n",
    "else:\n",
    "    print('No error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, not all the date values are in the correct format. Therefore we will have to iterate through each date value and determine which one of the follow formats the date value can be in:\n",
    "1. YYYY-MM-DD\n",
    "2. DD-MM-YYYY\n",
    "3. YYYY-DD-MM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dirty_df.iterrows():\n",
    "    new_row = pd.Series(row)\n",
    "\n",
    "    # Check if date fits the format YYYY-MM-DD\n",
    "    try:\n",
    "        new_row = pd.to_datetime(row['date'], format='%Y-%m-%d')\n",
    "    except:\n",
    "        # If not, check if it fits the format YYYY-DD-MM\n",
    "        try: \n",
    "            new_row = pd.to_datetime(row['date'], format='%Y-%d-%m')\n",
    "        # Else, check if it fits the format DD-MM-YYYY\n",
    "        except:\n",
    "            new_row = pd.to_datetime(row['date'], format='%d-%m-%Y')\n",
    "    dirty_df.at[index, 'date'] = new_row\n",
    "\n",
    "dirty_df['date'] = pd.to_datetime(dirty_df['date'], format='%Y-%m-%d').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate the `order_type` column. Since we know for certain that the time column does not have any errors in it, we can verify if the `order_type` is correct according to the time. The order should be the following according to the times:\n",
    "- 08:00:00 - 12:00:00 = Breakfast\n",
    "- 12:00:01 - 16:00:00 = Lunch\n",
    "- 16:00:01 - 20:00:00 = Dinner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Breakfast    170\n",
       "Lunch        165\n",
       "Dinner       165\n",
       "Name: order_type, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df['order_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if the correct order type has been inputted, we create the function `find_order-type`. It looks through each string time value in `time` column, converts this string into datetime format. Then we check the timestamp to see if it fits within the Breakfast, Lunch or Dinner time slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_order_type(time):\n",
    "    timestamp = pd.to_datetime(time, format='%H:%M:%S').time()\n",
    "    if timestamp >= pd.to_datetime('08:00:00').time() and timestamp <= pd.to_datetime('12:00:00').time():\n",
    "        return 'Breakfast'\n",
    "    elif timestamp >= pd.to_datetime('12:00:01').time() and timestamp < pd.to_datetime('16:00:00').time():\n",
    "        return 'Lunch'\n",
    "    elif timestamp >= pd.to_datetime('16:00:01').time() and timestamp <= pd.to_datetime('20:00:00').time():\n",
    "        return 'Dinner'\n",
    "    else:\n",
    "        return 'Error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>order_type</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>order_items</th>\n",
       "      <th>order_price</th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "      <th>customerHasloyalty?</th>\n",
       "      <th>distance_to_customer_KM</th>\n",
       "      <th>delivery_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ORDC09610</td>\n",
       "      <td>2018-10-06</td>\n",
       "      <td>17:07:36</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Fish&amp;Chips', 5), ('Shrimp', 2), ('Pasta', 4)]</td>\n",
       "      <td>393.0</td>\n",
       "      <td>-37.826028</td>\n",
       "      <td>144.984514</td>\n",
       "      <td>0</td>\n",
       "      <td>9.578</td>\n",
       "      <td>17.378357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ORDC06273</td>\n",
       "      <td>2018-09-05</td>\n",
       "      <td>16:06:45</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[('Pasta', 5), ('Shrimp', 10), ('Fish&amp;Chips', ...</td>\n",
       "      <td>1361.5</td>\n",
       "      <td>-37.814936</td>\n",
       "      <td>144.927351</td>\n",
       "      <td>0</td>\n",
       "      <td>10.813</td>\n",
       "      <td>16.896152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ORDB10659</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>11:32:57</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Eggs', 7), ('Coffee', 10), ('Cereal', 6), (...</td>\n",
       "      <td>597.5</td>\n",
       "      <td>-37.818900</td>\n",
       "      <td>144.952797</td>\n",
       "      <td>0</td>\n",
       "      <td>8.576</td>\n",
       "      <td>11.161592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ORDK01676</td>\n",
       "      <td>2018-03-16</td>\n",
       "      <td>10:21:58</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>BK</td>\n",
       "      <td>[('Eggs', 2), ('Pancake', 2)]</td>\n",
       "      <td>92.5</td>\n",
       "      <td>-37.801158</td>\n",
       "      <td>144.957692</td>\n",
       "      <td>0</td>\n",
       "      <td>8.326</td>\n",
       "      <td>13.278789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ORDB10190</td>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>17:17:44</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>TP</td>\n",
       "      <td>[('Fish&amp;Chips', 2), ('Salmon', 2)]</td>\n",
       "      <td>152.0</td>\n",
       "      <td>-37.813657</td>\n",
       "      <td>144.957285</td>\n",
       "      <td>0</td>\n",
       "      <td>8.419</td>\n",
       "      <td>13.088105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     order_id        date      time order_type branch_code  \\\n",
       "14  ORDC09610  2018-10-06  17:07:36      Lunch          NS   \n",
       "19  ORDC06273  2018-09-05  16:06:45      Lunch          NS   \n",
       "20  ORDB10659  2018-04-20  11:32:57     Dinner          TP   \n",
       "37  ORDK01676  2018-03-16  10:21:58     Dinner          BK   \n",
       "54  ORDB10190  2018-10-08  17:17:44  Breakfast          TP   \n",
       "\n",
       "                                          order_items  order_price  \\\n",
       "14   [('Fish&Chips', 5), ('Shrimp', 2), ('Pasta', 4)]        393.0   \n",
       "19  [('Pasta', 5), ('Shrimp', 10), ('Fish&Chips', ...       1361.5   \n",
       "20  [('Eggs', 7), ('Coffee', 10), ('Cereal', 6), (...        597.5   \n",
       "37                      [('Eggs', 2), ('Pancake', 2)]         92.5   \n",
       "54                 [('Fish&Chips', 2), ('Salmon', 2)]        152.0   \n",
       "\n",
       "    customer_lat  customer_lon  customerHasloyalty?  distance_to_customer_KM  \\\n",
       "14    -37.826028    144.984514                    0                    9.578   \n",
       "19    -37.814936    144.927351                    0                   10.813   \n",
       "20    -37.818900    144.952797                    0                    8.576   \n",
       "37    -37.801158    144.957692                    0                    8.326   \n",
       "54    -37.813657    144.957285                    0                    8.419   \n",
       "\n",
       "    delivery_fee  \n",
       "14     17.378357  \n",
       "19     16.896152  \n",
       "20     11.161592  \n",
       "37     13.278789  \n",
       "54     13.088105  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output values where calculated order type does not match the order type in the dataset\n",
    "dirty_df[dirty_df['time'].apply(find_order_type) != dirty_df['order_type']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, there are orders in which order type has been incorrectly inputted according to the time. We can fix this issue by performing the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_df['order_type'] = dirty_df['time'].apply(find_order_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dinner       170\n",
       "Breakfast    166\n",
       "Lunch        164\n",
       "Name: order_type, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df['order_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We determine if the branch and customer locations in `dirty_df` can be accurately found in the provided Graph in `nodes.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if customer node exists\n",
    "def check_customer_nodes(row):\n",
    "    customer_node = nodes_df[(nodes_df['lat'] == row['customer_lat']) & (nodes_df['lon'] == row['customer_lon'])]\n",
    "\n",
    "    if customer_node.empty:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# check if branch node exists\n",
    "def check_branch_nodes(row):\n",
    "    branch_lat = branch_df[branch_df['branch_code'] == row['branch_code']]['branch_lat'].values[0]\n",
    "    branch_lon = branch_df[branch_df['branch_code'] == row['branch_code']]['branch_lon'].values[0]\n",
    "\n",
    "    branch_node = nodes_df[(nodes_df['lat'] == branch_lat) & (nodes_df['lon'] == branch_lon)]\n",
    "\n",
    "    if branch_node.empty:\n",
    "        return True \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the number of rows where the customer node does not exist in the nodes.csv file\n",
    "dirty_df.apply(check_branch_nodes, axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results, we can see that all the branch nodes are accounted for and each node exists in the provided graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df.apply(check_customer_nodes, axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When checking for customer nodes, it is evident that there are 41 instances of orders where we are unable to identify the node in the graph according to the provided customer longitude and latitude values. To investigate further into the cause of this issue, let's output the first 15 instances where this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_lat</th>\n",
       "      <th>customer_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37.814994</td>\n",
       "      <td>144.960538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37.816395</td>\n",
       "      <td>144.938170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>37.816482</td>\n",
       "      <td>144.964894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>37.824000</td>\n",
       "      <td>144.953766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>37.811124</td>\n",
       "      <td>145.001788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>37.799866</td>\n",
       "      <td>145.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>37.814037</td>\n",
       "      <td>144.985480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>37.813155</td>\n",
       "      <td>144.968360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>37.804832</td>\n",
       "      <td>144.950241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>37.812135</td>\n",
       "      <td>144.962341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>37.806314</td>\n",
       "      <td>144.947357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>37.807900</td>\n",
       "      <td>144.991930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>145.005221</td>\n",
       "      <td>-37.817570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>37.812306</td>\n",
       "      <td>144.937522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>144.949738</td>\n",
       "      <td>-37.814165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     customer_lat  customer_lon\n",
       "5       37.814994    144.960538\n",
       "7       37.816395    144.938170\n",
       "12      37.816482    144.964894\n",
       "25      37.824000    144.953766\n",
       "35      37.811124    145.001788\n",
       "38      37.799866    145.002800\n",
       "45      37.814037    144.985480\n",
       "49      37.813155    144.968360\n",
       "52      37.804832    144.950241\n",
       "53      37.812135    144.962341\n",
       "61      37.806314    144.947357\n",
       "106     37.807900    144.991930\n",
       "135    145.005221    -37.817570\n",
       "151     37.812306    144.937522\n",
       "160    144.949738    -37.814165"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df[dirty_df.apply(check_customer_nodes, axis=1)][['customer_lat', 'customer_lon']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the outputted data above, we can see 2 prominent errors within the data:\n",
    "1. <b>There are some instances in which customer latitude has a missing negative symbol at the front. </b>\n",
    "\n",
    "Take the row at index 5 for example where latitude and longitude are 37.814994 and 144.960538 respectively. If we look at the `nodes.csv` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>6167489464</td>\n",
       "      <td>-37.814994</td>\n",
       "      <td>144.960538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            node        lat         lon\n",
       "3793  6167489464 -37.814994  144.960538"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 5\n",
    "# modify latitude by multiplying it by -1\n",
    "lat = dirty_df.loc[index,]['customer_lat'] * -1\n",
    "lon = dirty_df.loc[index,]['customer_lon']\n",
    "\n",
    "# check if the modified latitude exists in the nodes.csv file\n",
    "nodes_df[(nodes_df['lat'] == lat) & (nodes_df['lon'] == lon)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the following node exists in the graph when the latitude value is included with a negative value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. <b>There are some instance in which customer longitude and customer latitude are placed incorrectly and have been swapped with one another</b>\n",
    "\n",
    "Take row at index 135 for example where latitude and longitude are 145.005221 and -37.817570 respectively. It is evident that these have been inputted incorrectly and the values have swapped over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9191</th>\n",
       "      <td>1463620803</td>\n",
       "      <td>-37.81757</td>\n",
       "      <td>145.005221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            node       lat         lon\n",
       "9191  1463620803 -37.81757  145.005221"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 135\n",
    "# modify latitude by multiplying it by -1\n",
    "lat = dirty_df.loc[index,]['customer_lon']\n",
    "lon = dirty_df.loc[index,]['customer_lat']\n",
    "\n",
    "# check if the modified latitude exists in the nodes.csv file\n",
    "nodes_df[(nodes_df['lat'] == lat) & (nodes_df['lon'] == lon)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the following node exists in the graph when the customer latitude and longitude values are swapped over.\n",
    "\n",
    "We fix the issue with customer longitude and latitude values using the following custom function `find_customer_node` which first tries to find the node of the customer based on the given latitude and longitude values. If it is unable to do so, we try the following approaches next:\n",
    "1. Multiply the latitude value by negative and check to see if these coordinates exist in `nodes_df`. Else;\n",
    "2. Swap the longitude and latitude values and check to see if these coordinates exist in `nodes_df`\n",
    "\n",
    "If none of these approaches allow us to find a node, we will raise a `ValueError`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_customer_node(row):\n",
    "    cus_lat = row['customer_lat']\n",
    "    cus_lon = row['customer_lon']\n",
    "    customer_node = nodes_df[(nodes_df['lat'] == cus_lat) & (nodes_df['lon'] == cus_lon)]\n",
    "\n",
    "    # If the customer node does not exist, check for misinput of latitude and longitude values\n",
    "    if customer_node.empty:\n",
    "        # multiply the latitude by -1 \n",
    "        customer_node = nodes_df[(nodes_df['lat'] == -cus_lat) & (nodes_df['lon'] == cus_lon)]\n",
    "        # If the customer node still does not exist, try swapping the latitude and longitude values\n",
    "        if customer_node.empty:\n",
    "            customer_node = nodes_df[(nodes_df['lat'] == cus_lon) & (nodes_df['lon'] == cus_lat)]\n",
    "\n",
    "    # If the customer node still does not exist, raise an error\n",
    "    if customer_node.empty:\n",
    "        raise ValueError(\"Customer node does not exist in the nodes.csv file\")\n",
    "    \n",
    "    return customer_node.iloc[0]['lat'], customer_node.iloc[0]['lon']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_df['customer_coords'] = dirty_df.apply(calc_customer_node, axis=1)\n",
    "dirty_df[['customer_lat', 'customer_lon']] = pd.DataFrame(dirty_df['customer_coords'].to_list(), index=dirty_df.index)\n",
    "\n",
    "dirty_df.drop(columns=['customer_coords'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df.apply(check_customer_nodes, axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run `check_customer_nodes` again we can see that all of the coordinates can be accounted for and found in the `nodes.csv` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check if `distance_to_customer_KM` is correct. To start with this, we utilise `Graph()` function from `networkx` library to construct a Graph based on the nodes, edges provided by the Assignment brief in `nodes.csv` and `edges.csv` respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes_df['node'])\n",
    "for index, row in edges_df.iterrows():\n",
    "    G.add_edge(row['u'], row['v'], weight=row['distance(m)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_branch_node(row):\n",
    "    branch_lat = branch_df[branch_df['branch_code'] == row['branch_code']]['branch_lat'].values[0]\n",
    "    branch_lon = branch_df[branch_df['branch_code'] == row['branch_code']]['branch_lon'].values[0]\n",
    "\n",
    "    branch_node = nodes_df[(nodes_df['lat'] == branch_lat) & (nodes_df['lon'] == branch_lon)]\n",
    "\n",
    "    return branch_node\n",
    "\n",
    "def find_shortest_path(row):\n",
    "    cus_lat = row['customer_lat']\n",
    "    cus_lon = row['customer_lon']\n",
    "    customer_node = nodes_df[(nodes_df['lat'] == cus_lat) & (nodes_df['lon'] == cus_lon)]\n",
    "    \n",
    "    branch_node = find_branch_node(row)\n",
    "\n",
    "    # Find the shortest path between the customer node and the branch node\n",
    "    try:\n",
    "        # calculates the shortest path using djikstra's algorithm in M\n",
    "        shortest_path = nx.shortest_path_length(G, source=customer_node['node'].values[0], target=branch_node['node'].values[0], weight='weight')\n",
    "\n",
    "        # calculate to KM\n",
    "        shortest_path = shortest_path/1000\n",
    "    except nx.NetworkXNoPath:\n",
    "        raise ValueError(\"No path exists between the customer node and the branch node\")\n",
    "    \n",
    "    return shortest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_df['shortest_path'] = dirty_df.apply(find_shortest_path, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_to_customer_KM</th>\n",
       "      <th>shortest_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.914</td>\n",
       "      <td>8.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.330</td>\n",
       "      <td>7.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.667</td>\n",
       "      <td>7.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8.245</td>\n",
       "      <td>8.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.435</td>\n",
       "      <td>11.912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    distance_to_customer_KM  shortest_path\n",
       "1                     8.914          8.624\n",
       "11                    8.330          7.699\n",
       "15                    8.667          7.938\n",
       "18                    8.245          8.787\n",
       "22                    5.435         11.912"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df[dirty_df['distance_to_customer_KM'] != dirty_df['shortest_path']][['distance_to_customer_KM', 'shortest_path']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have correctly calculated the shortest distance to the customer according to Djikstra's algorithm, we replace the data in `distance_to_customer_KM` column with the correct distance data in `shortest_path` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_df['distance_to_customer_KM'] = dirty_df['shortest_path']\n",
    "dirty_df.drop(columns=['shortest_path'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if  `order_price` is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_df['order_items'] = dirty_df['order_items'].apply(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this code to determine all the menu items provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cereal',\n",
       " 'Eggs',\n",
       " 'Coffee',\n",
       " 'Pancake',\n",
       " 'Fries',\n",
       " 'Chicken',\n",
       " 'Salad',\n",
       " 'Burger',\n",
       " 'Salmon',\n",
       " 'Shrimp',\n",
       " 'Fish&Chips',\n",
       " 'Pasta',\n",
       " 'Steak']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df.explode('order_items')['order_items'].apply(lambda x: x[0]).unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "MENU_ITEMS = ['Cereal',\n",
    " 'Eggs',\n",
    " 'Coffee',\n",
    " 'Pancake',\n",
    " 'Fries',\n",
    " 'Chicken',\n",
    " 'Salad',\n",
    " 'Burger',\n",
    " 'Salmon',\n",
    " 'Shrimp',\n",
    " 'Fish&Chips',\n",
    " 'Pasta',\n",
    " 'Steak']\n",
    "\n",
    "def create_order_dict(row):\n",
    "    order_mapping = {item: index for index, item in enumerate(MENU_ITEMS)}\n",
    "    order = [0 for _ in MENU_ITEMS]\n",
    "    for item in row['order_items']:\n",
    "        order_index = order_mapping[item[0]]\n",
    "        order[order_index] += item[1]\n",
    "    return order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the clean data in missing_data.csv to determine the correct menu item price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df['order_items'] = missing_df['order_items'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_matrix = np.array(missing_df.apply(create_order_dict, axis=1).tolist())\n",
    "constants = np.array(missing_df['order_price'].tolist())\n",
    "solution, residuals, _, _ = np.linalg.lstsq(coef_matrix, constants, rcond=None)\n",
    "solution = solution.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We double check to see if the item price has been calculated correctly by finding the total order price for each order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prices = {item:price for item, price in zip(MENU_ITEMS, solution)}\n",
    "\n",
    "def calculate_order_price(row):\n",
    "    order_price = 0\n",
    "    for item in row['order_items']:\n",
    "        order_price += item[1] * item_prices[item[0]]\n",
    "    order_price = round(order_price, 2)\n",
    "    return order_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(missing_df['order_price'] != missing_df.apply(calculate_order_price, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown from above, we can be certain that all the item prices have been correctly calculated. Now we can use our calculated item prices to find the correct order prices within the `dirty_data.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_price</th>\n",
       "      <th>calc_order_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>387.6</td>\n",
       "      <td>856.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1104.5</td>\n",
       "      <td>1122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>235.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>289.0</td>\n",
       "      <td>541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>399.6</td>\n",
       "      <td>150.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_price  calc_order_price\n",
       "8         387.6             856.0\n",
       "21       1104.5            1122.0\n",
       "51        235.0             195.0\n",
       "59        289.0             541.0\n",
       "88        399.6             150.5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df['calc_order_price'] = dirty_df.apply(calculate_order_price, axis=1)\n",
    "dirty_df[dirty_df['order_price'] != dirty_df['calc_order_price']][['order_price', 'calc_order_price']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what we can see above, there are instances in `dirty_df` where the order_price does not align with the order price we have calculated. Since we know that the numeric quantity in order_items and our item prices are both correct, it would mean that the initial order price is incorrect. We fix these errors by assigning the values calculated in `calc_order_price` to `order_price`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_df['order_price'] = dirty_df['calc_order_price']\n",
    "dirty_df.drop(columns=['calc_order_price'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if `customerHasloyalty?` is correct. To verify if customerHasloyalty has been calculated correctly. We make use of the correct data in missing_data.csv again to create a logistic regression model to predict the customerHasLoyalty column. This logistic regression model, once generated will be able to correctly calculate the data in dirty_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_timeOfDay(order_type):\n",
    "    if order_type == 'Breakfast':\n",
    "        return 0\n",
    "    elif order_type == 'Lunch':\n",
    "        return 1\n",
    "    elif order_type == 'Dinner':\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if pd.datetime.dayofweek is greater than or equal to 5. Monday=0, Sunday=6\n",
    "temp_df = missing_df.dropna(subset=['date', 'order_type', 'branch_code', 'distance_to_customer_KM', 'delivery_fee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-169-959cc33addc4>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df['weekend?']=temp_df['date'].apply(lambda x: pd.to_datetime(x).dayofweek >= 5)\n",
      "<ipython-input-169-959cc33addc4>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df['timeofday'] = temp_df['order_type'].apply(calc_timeOfDay)\n"
     ]
    }
   ],
   "source": [
    "temp_df['weekend?']=temp_df['date'].apply(lambda x: pd.to_datetime(x).dayofweek >= 5)\n",
    "temp_df['timeofday'] = temp_df['order_type'].apply(calc_timeOfDay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "BK_df = temp_df[temp_df['branch_code'] == 'BK']\n",
    "NS_df = temp_df[temp_df['branch_code'] == 'NS']\n",
    "TP_df = temp_df[temp_df['branch_code'] == 'TP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "# Assuming your data is stored in a DataFrame called df\n",
    "\n",
    "# Split your data into features (X) and target variable (y)\n",
    "X = BK_df[['weekend?', 'timeofday', 'distance_to_customer_KM', 'delivery_fee']]  # Features\n",
    "y = BK_df['customerHasloyalty?']  # Target variable\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize logistic regression model\n",
    "BK_log_model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "BK_log_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = BK_log_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Additional evaluation metrics\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Split your data into features (X) and target variable (y)\n",
    "X = NS_df[['weekend?', 'timeofday', 'distance_to_customer_KM', 'delivery_fee']]  # Features\n",
    "y = NS_df['customerHasloyalty?']  # Target variable\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize logistic regression model\n",
    "NS_log_model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "NS_log_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = NS_log_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Split your data into features (X) and target variable (y)\n",
    "X = TP_df[['weekend?', 'timeofday', 'distance_to_customer_KM', 'delivery_fee']]  # Features\n",
    "y = TP_df['customerHasloyalty?']  # Target variable\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize logistic regression model\n",
    "TP_log_model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "TP_log_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = TP_log_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_df['weekend?'] = dirty_df['date'].apply(lambda x: pd.to_datetime(x).dayofweek >= 5)\n",
    "dirty_df['timeofday'] = dirty_df['order_type'].apply(calc_timeOfDay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirty_df[dirty_df['branch_code'] == 'BK']['calc_loyalty'] =  BK_log_model.predict(dirty_df[dirty_df['branch_code'] == 'BK'][['weekend?', 'timeofday', 'distance_to_customer_KM', 'delivery_fee']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirty_df[['branch_code', 'order_price', 'distance_to_customer_KM', 'delivery_fee']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_df['BK_loyalty'] = BK_log_model.predict(dirty_df[['weekend?', 'timeofday', 'distance_to_customer_KM', 'delivery_fee']])\n",
    "dirty_df['NS_loyalty'] = NS_log_model.predict(dirty_df[['weekend?', 'timeofday', 'distance_to_customer_KM', 'delivery_fee']])\n",
    "dirty_df['TP_loyalty'] = TP_log_model.predict(dirty_df[['weekend?', 'timeofday', 'distance_to_customer_KM', 'delivery_fee']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loyalty(row):\n",
    "    if row['branch_code'] == 'BK':\n",
    "        return row['BK_loyalty']\n",
    "    elif row['branch_code'] == 'NS':\n",
    "        return row['NS_loyalty']\n",
    "    elif row['branch_code'] == 'TP':\n",
    "        return row['TP_loyalty']\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_df['calc_loyalty'] = dirty_df.apply(calc_loyalty, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerHasloyalty?</th>\n",
       "      <th>calc_loyalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     customerHasloyalty?  calc_loyalty\n",
       "2                      1             0\n",
       "13                     1             0\n",
       "62                     1             0\n",
       "67                     1             0\n",
       "75                     1             0\n",
       "80                     1             0\n",
       "85                     0             1\n",
       "125                    1             0\n",
       "156                    1             0\n",
       "157                    1             0"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df[dirty_df['calc_loyalty'] != dirty_df['customerHasloyalty?']][['customerHasloyalty?', 'calc_loyalty']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dirty_df['calc_loyalty'] != dirty_df['customerHasloyalty?']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, we can see that in the original data, customerHasloyaty has been inputted incorrectly for 39 orders. We know that the data is issue as our logisticregression models have a 100% accuracy. Knowing this, we assign the values from `calc_loyalty` to `customerHasloyalty?` to remove the dirty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_df['customerHasloyalty?'] = dirty_df['calc_loyalty']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that our data has been cleaned property, we create another logistic regression model for the data in `dirty_df` to see if the accuracy of the model is 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "BK_df = dirty_df[dirty_df['branch_code'] == 'BK']\n",
    "NS_df = dirty_df[dirty_df['branch_code'] == 'NS']\n",
    "TP_df = dirty_df[dirty_df['branch_code'] == 'TP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      BK\n",
       "1      NS\n",
       "2      NS\n",
       "3      NS\n",
       "4      BK\n",
       "       ..\n",
       "495    NS\n",
       "496    BK\n",
       "497    TP\n",
       "498    TP\n",
       "499    TP\n",
       "Name: branch_code, Length: 500, dtype: object"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df['branch_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BK branch customerHasLoyalty Accuracy: 1.0\n",
      "NS branch customerHasLoyalty Accuracy: 1.0\n",
      "TP branch customerHasLoyalty Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "# Assuming your data is stored in a DataFrame called df\n",
    "\n",
    "# Split your data into features (X) and target variable (y)\n",
    "X = BK_df[['weekend?', 'timeofday', 'distance_to_customer_KM', 'delivery_fee']]  # Features\n",
    "y = BK_df['customerHasloyalty?']  # Target variable\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize logistic regression model\n",
    "BK_log_model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "BK_log_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = BK_log_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"BK branch customerHasLoyalty Accuracy:\", accuracy)\n",
    "\n",
    "# Additional evaluation metrics\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Split your data into features (X) and target variable (y)\n",
    "X = NS_df[['weekend?', 'timeofday', 'distance_to_customer_KM', 'delivery_fee']]  # Features\n",
    "y = NS_df['customerHasloyalty?']  # Target variable\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize logistic regression model\n",
    "NS_log_model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "NS_log_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = NS_log_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"NS branch customerHasLoyalty Accuracy:\", accuracy)\n",
    "\n",
    "# Split your data into features (X) and target variable (y)\n",
    "X = TP_df[['weekend?', 'timeofday', 'distance_to_customer_KM', 'delivery_fee']]  # Features\n",
    "y = TP_df['customerHasloyalty?']  # Target variable\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize logistic regression model\n",
    "TP_log_model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "TP_log_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = TP_log_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"TP branch customerHasLoyalty Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO NEED TO SEPARATE MODEL INTO THREE'S ONLY NEED TO CONVERT BRANCH INTO NUMERICAL ATTRIBUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['BK_loyalty' 'NS_loyalty' 'TP_loyalty' 'calc_loyalty'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-207-70e61c939a26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#  remove generated columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdirty_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weekend?'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'timeofday'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BK_loyalty'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NS_loyalty'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TP_loyalty'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'calc_loyalty'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mg:\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4306\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4307\u001b[0m         \"\"\"\n\u001b[1;32m-> 4308\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4309\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4310\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4151\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4153\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4186\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4188\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4189\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5589\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5590\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5591\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5592\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5593\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['BK_loyalty' 'NS_loyalty' 'TP_loyalty' 'calc_loyalty'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#  remove generated columns\n",
    "dirty_df.drop(columns=['weekend?', 'timeofday', 'BK_loyalty', 'NS_loyalty', 'TP_loyalty', 'calc_loyalty'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Imputating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
